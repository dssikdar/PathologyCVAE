# PathologyCVAE

# Anomaly Detection in Breast Histopathology Images with Convolutional Variational Autoencoders

## ğŸ“Œ Overview
We explore the use of **Convolutional Variational Autoencoders (ConvVAE)** for anomaly detection in breast histopathological images. Our study compares ConvVAEs against Fully Connected VAEs (FC-VAEs) and attention-based architectures for distinguishing cancerous and non-cancerous tissue samples. The implemented models include:

1. **Baseline Variational Autoencoder (VAE)** â€“ lacks spatial awareness.
2. **Standard ConvVAE** â€“ utilizes convolutional layers for feature extraction.
3. **VAE with a Pre-trained U-Net Encoder** â€“ leverages a ResNet-34 encoder for improved representation learning.
4. **Attentive ConvVAE** â€“ integrates attention mechanisms to enhance feature learning.

Our findings indicate that ConvVAEs outperform simple VAEs, emphasizing the importance of convolutional layers for effective feature extraction. Among convolution-based models, ConvVAE achieves the highest classification accuracy and AUC, making it the best-performing model overall.

## ğŸš€ Project Motivation
Breast cancer is one of the most commonly diagnosed cancers worldwide. Early detection significantly improves survival rates, but traditional histopathological diagnosis is time-consuming and subjective. We investigate how **unsupervised deep learning models**, particularly Variational Autoencoders, can improve automated anomaly detection for breast histopathology images, reducing diagnostic variability and aiding pathologists.

## ğŸ“Š Dataset
We use the **Breast Histopathology Images** dataset from Kaggle, which includes:
- **277,524** image patches of size **50 Ã— 50** extracted from **162 whole-mount slide images (WSI)**.
- Binary labels:
  - **198,738 IDC-negative (non-cancerous) samples**
  - **78,786 IDC-positive (cancerous) samples**

ğŸ”— Dataset Link: [Kaggle: Breast Histopathology Images](https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images/data)

## ğŸ” Demo
### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/yourusername/cancer-anomaly-detection.git
cd cancer-anomaly-detection
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Train the Model
```bash
python train.py --epochs 50 --batch_size 64
```

### 4ï¸âƒ£ Evaluate the Model
```bash
python evaluate.py --model_path saved_model.pth
```

### 5ï¸âƒ£ Run Demo (Inference)
```bash
python demo.py --input sample_image.jpg
```

## ğŸ“ Results
### Model Performance Summary
| Model | Reconstruction Loss | KL Divergence | Accuracy (%) | F1 Score | AUC |
|--------|----------------------|--------------|--------------|----------|------|
| VAE | 1075.94 | 48.71 | 54.43 | 0.41 | 0.53 |
| ConvVAE | **424.14** | 261.09 | **65.58** | 0.64 | **0.70** |
| Attn-ConvVAE | **374.57** | 392.12 | 57.89 | 0.63 | 0.60 |
| Frozen CVAE-U-Net | 639.11 | **20.01** | 51.78 | **0.65** | 0.50 |
| Unfrozen CVAE-U-Net | 540.59 | **12.35** | 53.99 | 0.64 | 0.53 |

**Key Findings:**
- **ConvVAE achieved the highest accuracy (65.58%) and AUC (0.70)**, making it the best overall model for anomaly detection.
- **Attn-ConvVAE had the lowest reconstruction loss (374.57)** but performed slightly worse in classification.
- **U-Net-based models had the lowest KL divergence**, suggesting effective latent space regularization but weaker classification performance.

## ğŸ“œ Report
For an in-depth discussion of our methodology, experiments, and findings, check out our **full report**:
ğŸ“„ [Project Report (PDF)](link_to_report.pdf)

## ğŸ“ Repository Structure
```
ğŸ“‚ cancer-anomaly-detection
 â”œâ”€â”€ ğŸ“œ README.md            # Project documentation
 â”œâ”€â”€ ğŸ“ data                 # Data (not included due to size)
 â”œâ”€â”€ ğŸ“ models               # Saved trained models
 â”œâ”€â”€ ğŸ“ src                  # Source code
 â”‚   â”œâ”€â”€ train.py            # Training script
 â”‚   â”œâ”€â”€ evaluate.py         # Evaluation script
 â”‚   â”œâ”€â”€ demo.py             # Inference/demo script
 â”‚   â”œâ”€â”€ dataset.py          # Data loading and preprocessing
 â”‚   â”œâ”€â”€ conv_vae.py         # Model architecture
 â”œâ”€â”€ ğŸ“ notebooks            # Jupyter notebooks for analysis
 â”œâ”€â”€ requirements.txt        # Dependencies
 â””â”€â”€ .gitignore              # Ignore unnecessary files
```

## ğŸ¤ Contributors
ğŸ‘¤ **Diptanshu Sikdar:**  
ğŸ“§ Email: dsikdar@uci.edu  

ğŸ‘¤ **Travis Tran:**  
ğŸ“§ Email: travitt1@uci.edu  

ğŸ‘¤ **James Xu:**  
ğŸ“§ Email: xujg@uci.edu  

ğŸ‘¤ **Jordan Yee:**  
ğŸ“§ Email: jordady1@uci.edu  

## ğŸ“Œ Future Work
- **Explore higher-resolution datasets** to assess model generalization.
- **Enhance preprocessing** using denoising techniques (e.g., Non-Local Means, Wavelet-Based Denoising).
- **Improve feature extraction** by integrating multi-head attention mechanisms.
- **Apply transfer learning** from larger medical imaging datasets to refine model weights.

## â­ Acknowledgments
Special thanks to **UCI CS 175: Project in AI** for the opportunity to work on this project.
