# PathologyCVAE

# Convolutional Variational Autoencoder for Cancer Detection

## ğŸ“Œ Overview
This repository contains the code, trained models, and analysis for our **Convolutional Variational Autoencoder (ConvVAE)** project, aimed at anomaly detection in **lung and colon cancer histopathological images**. Our goal is to leverage deep generative models to distinguish between **cancerous and non-cancerous** tissue samples, aiding early-stage cancer detection.

## ğŸš€ Project Motivation
Cancer diagnosis through histopathological images requires expert annotation, which is time-intensive and costly. Our **ConvVAE** model aims to **learn the underlying distribution of healthy tissue** and detect anomalies that may correspond to cancerous regions, providing an **unsupervised learning** approach to assist pathologists.

## ğŸ—ï¸ Model Architecture
Our **Convolutional Variational Autoencoder (ConvVAE)** consists of three main components:

### âœ¨ Encoder
- **4 convolutional layers** (Conv2D) with BatchNorm and ReLU activation.
- Strided convolutions to reduce feature map dimensions.
- Fully connected layers to output **mean (`Î¼`)** and **log variance (`logÏƒÂ²`)**.

### ğŸ”— Latent Space
- `Î¼` and `logÏƒÂ²` are used for **reparameterization trick** to sample `z`.
- Fully connected layer maps `z` back to feature space.

### ğŸ¨ Decoder
- **4 transposed convolutional layers** (ConvTranspose2D) with BatchNorm and ReLU activation.
- Final output layer with **Tanh() activation** for image reconstruction.

## ğŸ“Š Dataset
We use the **Lung and Colon Cancer Histopathological Images Dataset** from Kaggle. It contains:
- **15,000 images** of lung and colon tissue samples.
- Labeled as **cancerous vs. non-cancerous**.

ğŸ”— Dataset Link: [Kaggle: Lung and Colon Cancer Images](https://www.kaggle.com/datasets/andrewmvd/lung-and-colon-cancer-histopathological-images)

## ğŸ” Usage
### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/yourusername/cancer-anomaly-detection.git
cd cancer-anomaly-detection
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Train the Model
```bash
python train.py --epochs 50 --batch_size 64
```

### 4ï¸âƒ£ Evaluate the Model
```bash
python evaluate.py --model_path saved_model.pth
```

### 5ï¸âƒ£ Run Demo (Inference)
```bash
python demo.py --input sample_image.jpg
```

## ğŸ“ Results
Our experiments demonstrate that the **ConvVAE effectively reconstructs normal (non-cancerous) tissue**, while **cancerous samples exhibit higher reconstruction error**, making them identifiable as anomalies. Key observations:
- The model achieves **low reconstruction loss for normal samples**.
- Cancerous samples **show high reconstruction errors**, enabling detection.
- The learned latent space provides **meaningful representations** of tissue features.

## ğŸ“œ Report
For an in-depth discussion of our methodology, experiments, and findings, check out our **full report**:
ğŸ“„ [Project Report (PDF)](link_to_report.pdf)

## ğŸ“ Repository Structure
```
ğŸ“‚ cancer-anomaly-detection
 â”œâ”€â”€ ğŸ“œ README.md            # Project documentation
 â”œâ”€â”€ ğŸ“ data                 # Data (not included due to size)
 â”œâ”€â”€ ğŸ“ models               # Saved trained models
 â”œâ”€â”€ ğŸ“ src                  # Source code
 â”‚   â”œâ”€â”€ train.py            # Training script
 â”‚   â”œâ”€â”€ evaluate.py         # Evaluation script
 â”‚   â”œâ”€â”€ demo.py             # Inference/demo script
 â”‚   â”œâ”€â”€ dataset.py          # Data loading and preprocessing
 â”‚   â”œâ”€â”€ conv_vae.py         # Model architecture
 â”œâ”€â”€ ğŸ“ notebooks            # Jupyter notebooks for analysis
 â”œâ”€â”€ requirements.txt        # Dependencies
 â””â”€â”€ .gitignore              # Ignore unnecessary files
```

## ğŸ¤ Contributors
ğŸ‘¤ **Diptanshu Sikdar**  
ğŸ“§ Email: dsikdar@uci.edu  

ğŸ‘¤ **Travis Tran:**
ğŸ“§ Email: travitt1@uci.edu

ğŸ‘¤ **James Xu:** 
ğŸ“§ Email: xujg@uci.edu

ğŸ‘¤ **Jordan Yee:** 
ğŸ“§ Email: jordady1@uci.edu

## ğŸ“Œ Future Work
- Experiment with **different VAE architectures** (e.g., Î²-VAE, WAE).
- Use **self-supervised contrastive learning** to improve feature extraction.
- Fine-tune model using **GAN-based approaches** for enhanced reconstruction.

## â­ Acknowledgments
Special thanks to **UCI CS 175: Project in AI** for the opportunity to work on this project.
